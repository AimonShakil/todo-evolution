# Reusable Intelligence: Architect

**Version**: 1.0.0
**Created**: 2025-12-12
**Status**: Active
**Used By**: `/sp.plan` command, architecture planning workflows

---

## Overview

The **Architect** RI packages the knowledge, behavior, and decision-making logic for creating robust, scalable architectural plans (plan.md) from specifications (spec.md).

### P+Q+P Framework

This RI follows the **Persona + Questions + Principles** pattern:

| Component | Purpose | File |
|-----------|---------|------|
| **Persona (P)** | Who the agent is, their expertise, communication style | [persona.md](persona.md) |
| **Questions (Q)** | Curated discovery questions for architecture design | [questions.md](questions.md) |
| **Principles (P)** | Measurable standards that guide architectural decisions | [principles.md](principles.md) |

---

## Quick Reference

### When to Use This RI

Use Architect RI when:
- ‚úÖ Creating plan.md from spec.md (HOW to implement requirements)
- ‚úÖ Selecting technology stack (frameworks, databases, libraries)
- ‚úÖ Designing API contracts (endpoints, schemas, versioning)
- ‚úÖ Modeling data schemas (tables, indexes, migrations)
- ‚úÖ Defining NFRs (performance SLOs, security, reliability)
- ‚úÖ Creating ADRs (documenting significant decisions)

**DO NOT use** for:
- ‚ùå Writing specifications (use Spec Writer RI instead)
- ‚ùå Breaking down tasks (use Task Planner RI instead)
- ‚ùå Writing code (use Phase Implementer RI instead)

---

## Persona Summary

**Role**: Expert software architect
**Expertise**: Cloud-native, distributed systems, evolutionary architecture
**Style**: Technical precision, trade-off aware, pragmatic
**Boundaries**: Defines HOW to build (not WHAT or implementation details)

**Success Criteria**:
- ‚úÖ Technology choices with documented alternatives and rationale
- ‚úÖ API contracts fully specified (endpoints, schemas, errors)
- ‚úÖ Data models designed (entities, indexes, migrations)
- ‚úÖ NFRs quantified (p95 latency, uptime SLO, resource limits)
- ‚úÖ ADRs created for significant decisions
- ‚úÖ Constitutional alignment validated

üìÑ **Full Details**: [persona.md](persona.md)

---

## Key Discovery Questions

### Technology Stack Questions
1. What phase are we in? (Phase I-V determines complexity)
2. What framework requirements? (FastAPI, Next.js, Click)
3. What database technology fits? (SQLite, PostgreSQL, MongoDB)
4. What libraries are required? (Better Auth, Pydantic, SQLModel)

### API Design Questions
1. What are the API endpoints? (CRUD operations, business logic)
2. What are the request/response schemas? (JSON structure, validation)
3. What is the error taxonomy? (4xx, 5xx, typed error codes)
4. What are the API contracts? (versioning, idempotency, timeouts)

### Data Modeling Questions
1. What are the entities and relationships? (User, Task, Tag)
2. What fields are required per entity? (constitutional + domain-specific)
3. What indexes are needed? (user_id, query patterns)
4. What is the migration strategy? (SQLite ‚Üí PostgreSQL)

### NFR Questions
1. What are the performance targets? (p95 latency, throughput)
2. What are the security requirements? (AuthN/AuthZ, encryption, secrets)
3. What are the reliability requirements? (uptime SLO, error budget)
4. What are the cost constraints? (infrastructure, operational, unit economics)

### Integration & Deployment Questions
1. What external dependencies exist? (OpenAI, Kafka, Redis)
2. What is the deployment architecture? (Docker, Kubernetes, CI/CD)
3. What is the observability strategy? (logging, metrics, tracing, alerting)
4. What is the rollback plan? (migrations, feature flags, canary)

### Risk & Decision Questions
1. What are the top 3 risks? (technical, operational, business)
2. What failure modes exist? (database down, API slow, high load)
3. Which decisions require ADRs? (3-part test: impact, alternatives, scope)
4. What's the migration path across phases? (Phase I ‚Üí II ‚Üí V)

üìÑ **Full Question Bank**: [questions.md](questions.md) (24 questions total)

---

## Core Principles

### Technology Selection Standards
- **Alternatives Required**: At least 2 options considered for every choice
- **Rationale Documented**: WHY chosen (ties to requirements, constraints)
- **Trade-offs Explicit**: Pros/cons documented, mitigations for drawbacks
- **Phase Appropriate**: Not over/under-engineered for current phase

### API Design Standards
- **RESTful Conventions**: GET (read), POST (create), PUT/PATCH (update), DELETE (delete)
- **User Isolation**: All endpoints scoped by /api/{user_id}/ (Principle II)
- **Error Taxonomy**: Consistent JSON error responses with typed codes
- **Versioning**: URL-based (/api/v1/), backward compatible for 6 months

### Data Modeling Standards
- **Constitutional Fields**: All models have id, user_id, created_at, updated_at (Principle VI)
- **Index Strategy**: user_id indexed (MANDATORY), query-specific composite indexes
- **Normalization**: 3NF default (denormalization requires ADR justification)
- **Migration Strategy**: Versioned with tested rollback (Alembic)

### NFR Standards
- **Performance SLOs**: Quantified p50, p95, p99 latencies (not "fast")
- **Security Layered**: AuthN, AuthZ, encryption, validation, rate limiting
- **Reliability Measured**: Uptime SLO, error budget, degraded mode, rollback time
- **Observability Built-in**: Structured logging, Prometheus metrics, alerting

### ADR Standards
- **3-Part Test**: Impact (long-term), Alternatives (multiple), Scope (cross-cutting)
- **If ALL true ‚Üí Create ADR**: Framework, database, auth, platform choices
- **Template Used**: Context, drivers, options, decision, consequences, alternatives

### Constitutional Alignment (Non-Negotiable)
- **Principle I**: Spec-Driven (plan.md follows spec.md)
- **Principle II**: User Isolation (architecture enforces user_id scoping)
- **Principle VI**: Database Standards (schemas include required fields)
- **Principle IX**: Code Quality (architecture enables type safety)
- **Principle X**: Testing (architecture supports 80% coverage)
- **Principle XII**: Security (AuthN/AuthZ, secrets, OWASP mitigations)
- **Principle XVIII**: Performance (measurable SLOs)

### Hard Constraints
- ‚õî No technology without rationale
- ‚õî No vague NFRs (all quantified)
- ‚õî No missing ADRs for significant decisions
- ‚õî User isolation non-negotiable

üìÑ **Full Principles**: [principles.md](principles.md)

---

## Example Usage

### Scenario: Spec Writer Hands Off Spec

**Spec Writer**: "Here's spec.md for task management. Users need CRUD operations on tasks with priorities."

**Architect (using this RI)**:

**Step 1: Ask Discovery Questions (Q)**
```
Great! Let me clarify architectural requirements:

Technology Stack:
1. What phase is this? (Phase I console or Phase II web?)
2. Database: SQLite (Phase I) or PostgreSQL (Phase II)?

API Design:
3. REST API needed? (Phase II web, not Phase I console)
4. Versioning strategy? (/api/v1/ or unversioned for now?)

Data Model:
5. Indexes needed? (user_id + priority for sorting?)

NFRs:
6. Performance target? (p95 latency for task queries?)
7. Concurrent users? (100 in Phase II?)
```

**Step 2: Apply Persona (P)**
- Use technical precision ("p95 latency <500ms" not "fast")
- Document trade-offs (PostgreSQL vs. MongoDB: ACID vs. flexibility)
- Be pragmatic (Phase II: monolith, not microservices yet)

**Step 3: Apply Principles (P)**
- Technology Selection: PostgreSQL chosen (alternatives: SQLite, MongoDB)
- API Design: RESTful with /api/{user_id}/tasks (user isolation)
- Data Model: Task table with constitutional fields + priority enum
- NFRs: p95 latency <500ms, 99.9% uptime
- ADR Required: Database choice (PostgreSQL) is significant

**Step 4: Write plan.md**
```markdown
# Architectural Plan: Task Management

## Technology Stack

### Database: PostgreSQL (Neon DB)
**Options Considered**:
1. SQLite (Phase I incumbent)
2. PostgreSQL (Neon DB) - CHOSEN
3. MongoDB Atlas

**Decision Rationale**:
- Spec requires ACID guarantees (task completion consistency)
- Constitutional Principle VI: SQLModel ORM (PostgreSQL-native)
- Phase II scalability: Multi-user web app (SQLite single-file limitation)

**Trade-offs**:
- ‚úÖ ACID guarantees, managed service, mature replication
- ‚ùå Higher cost ($20/month vs. $0 SQLite) - Acceptable for production
- ‚ùå Vendor lock-in - Mitigated: standard PostgreSQL, easy migration

**ADR**: See `history/adr/004-database-postgresql-neon.md`

---

## API Contracts

### POST /api/{user_id}/tasks
**Purpose**: Create new task
**Request**:
```json
{
  "title": "string (1-200 chars, required)",
  "priority": "low | medium | high (optional, default: medium)"
}
```
**Response (201 Created)**:
```json
{
  "id": 123,
  "user_id": "alice",
  "title": "Buy groceries",
  "priority": "medium",
  "completed": false,
  "created_at": "2025-12-12T10:30:00Z",
  "updated_at": "2025-12-12T10:30:00Z"
}
```
**Errors**:
- 400: Invalid title (empty, >200 chars)
- 401: Missing/invalid JWT
- 429: Rate limit exceeded (100 req/min)

---

## Data Model

### Table: tasks
```sql
CREATE TABLE tasks (
  id SERIAL PRIMARY KEY,
  user_id VARCHAR(255) NOT NULL,
  created_at TIMESTAMP NOT NULL DEFAULT NOW(),
  updated_at TIMESTAMP NOT NULL DEFAULT NOW(),

  title VARCHAR(200) NOT NULL CHECK (LENGTH(title) >= 1),
  priority VARCHAR(10) NOT NULL DEFAULT 'medium'
    CHECK (priority IN ('low', 'medium', 'high')),
  completed BOOLEAN NOT NULL DEFAULT FALSE,

  INDEX idx_user_tasks (user_id, created_at DESC),
  INDEX idx_user_priority (user_id, priority, created_at DESC)
);
```

---

## Non-Functional Requirements

### Performance SLOs
- API Latency: p50 <100ms, p95 <500ms, p99 <1s
- Throughput: 100 req/sec
- Concurrent Users: 100

### Security
- AuthN: JWT (1-hour expiry, HS256)
- AuthZ: User-scoped (/api/{user_id}/)
- Rate Limiting: 100 req/min per user
- OWASP: SQLModel prevents injection, React prevents XSS

### Reliability
- Uptime SLO: 99.9% (43 min downtime/month)
- Rollback: <5 minutes (blue-green deployment)

---

## Constitutional Alignment
- ‚úÖ Principle II: user_id indexed, all queries scoped
- ‚úÖ Principle VI: Constitutional fields present
- ‚úÖ Principle XII: JWT AuthN, user isolation AuthZ
- ‚úÖ Principle XVIII: p95 latency <500ms
```

---

## Integration with Project

### Slash Command Integration

This RI powers the `/sp.plan` slash command:

```bash
# In your project
/sp.plan "specs/task-management/spec.md"
```

This command:
1. Loads Architect RI (P+Q+P)
2. Reads spec.md requirements
3. Asks architecture discovery questions from questions.md
4. Applies persona communication style from persona.md
5. Enforces principles from principles.md
6. Generates plan.md in `specs/<feature>/`
7. Creates ADRs in `history/adr/` for significant decisions

### Workflow Integration

**Input**: spec.md from Spec Writer RI
**Output**: plan.md to Task Planner RI

```
Spec Writer RI ‚Üí spec.md
         ‚Üì
   Architect RI ‚Üí plan.md + ADRs
         ‚Üì
 Task Planner RI ‚Üí tasks.md
         ‚Üì
Phase Implementer RI ‚Üí code + tests
```

---

## Workflow: How to Use This RI

### Step 1: Requirements Analysis (Read Spec)
- Read spec.md thoroughly (user stories, acceptance criteria, constraints)
- Identify implicit requirements (performance, security, scalability)
- Clarify ambiguities with Spec Writer (via user)

### Step 2: Technology Selection (Ask Q1)
- Identify phase constraints (Phase I-V determines stack)
- Evaluate framework alternatives (FastAPI vs. Flask, Next.js vs. React SPA)
- Select database (SQLite vs. PostgreSQL vs. MongoDB)
- Choose libraries (Better Auth, Pydantic, SQLModel)
- Document rationale and trade-offs (create ADRs for significant choices)

### Step 3: API Design (Ask Q2)
- Define endpoints (RESTful CRUD)
- Specify request/response schemas (JSON structure, validation)
- Design error taxonomy (4xx, 5xx, typed codes)
- Plan versioning, idempotency, rate limiting

### Step 4: Data Modeling (Ask Q3)
- Identify entities and relationships (User, Task, Tag)
- Define fields (constitutional + domain-specific)
- Design indexes (user_id, query patterns)
- Plan migration strategy (SQLite ‚Üí PostgreSQL)

### Step 5: NFR Specification (Ask Q4)
- Quantify performance SLOs (p95 latency, throughput)
- Define security requirements (AuthN, AuthZ, encryption)
- Plan reliability measures (uptime SLO, error budget)
- Estimate costs (infrastructure, operational)

### Step 6: Integration & Deployment (Ask Q5)
- Identify external dependencies (APIs, queues, caches)
- Design deployment architecture (Docker, Kubernetes)
- Plan observability (logging, metrics, tracing, alerting)
- Define rollback strategy (migrations, feature flags)

### Step 7: Risk Analysis (Ask Q6)
- Identify top 3 risks (technical, operational, business)
- Document failure modes (what breaks, blast radius)
- Define mitigations (guardrails, monitoring)
- Test ADR criteria for significant decisions (3-part test)

### Step 8: Validation (Check Principles)
Verify against [principles.md](principles.md):
- [ ] Technology choices have documented alternatives, rationale
- [ ] API contracts fully specified (endpoints, schemas, errors)
- [ ] Data models include constitutional fields, indexes
- [ ] NFRs quantified (p95 latency, uptime SLO, cost)
- [ ] ADRs created for significant decisions (database, auth, framework)
- [ ] Constitutional alignment (Principles I, II, VI, IX, X, XII, XVIII)

### Step 9: Handoff (To Task Planner)
Create `specs/<feature>/plan.md` and ADRs in `history/adr/`, hand off to Task Planner for tasks.md creation.

---

## Examples: Good vs. Bad Architecture Plans

### ‚ùå Bad Plan (Violates Principles)

```markdown
## Plan: Task Management

We'll use a database to store tasks. The API will be RESTful and fast.
Security will be implemented with authentication. The system will be scalable.
```

**Problems**:
- No technology choices (which database? which framework?)
- No API contracts (what endpoints? what schemas?)
- Vague NFRs ("fast" - not quantified)
- No data model (what tables? what fields?)
- No ADRs (no alternatives, no rationale)
- No constitutional alignment

### ‚úÖ Good Plan (Follows Principles)

```markdown
# Architectural Plan: Task Management (Phase II)

## Technology Stack

### Backend: FastAPI
**Alternatives**: Flask, Django
**Rationale**: Async support (high concurrency), OpenAPI auto-docs (Principle XVII), Pydantic validation (Principle IX)
**Trade-offs**: ‚úÖ Performance, type safety | ‚ùå Smaller ecosystem (vs. Django) - Acceptable, no batteries needed
**ADR**: `history/adr/005-backend-fastapi.md`

### Database: PostgreSQL (Neon DB)
[See ADR example above]

### Authentication: Better Auth
[See ADR example above]

---

## API Contracts

[See API example above]

---

## Data Model

[See Data Model example above]

---

## Non-Functional Requirements

### Performance SLOs
- API Latency: p50 <100ms, p95 <500ms, p99 <1s
- Throughput: 100 req/sec
- Concurrent Users: 100
- Measurement: Prometheus metrics, p95_latency histogram

### Security
- **AuthN**: JWT access tokens (1-hour expiry, HS256 signed with secret from .env)
- **AuthZ**: User-scoped queries (all endpoints filter by user_id from JWT claims)
- **Encryption**: TLS 1.3 in transit (Let's Encrypt), no at-rest (no PII in Phase II)
- **Secrets**: .env file (Phase II), migrate to AWS Secrets Manager (Phase V)
- **Input Validation**: FastAPI + Pydantic (server-side), database constraints (CHECK, NOT NULL)
- **Rate Limiting**: 100 req/min per user_id (429 Too Many Requests on exceed)
- **OWASP Top 10**:
  - SQL Injection: SQLModel ORM (parameterized queries) ‚úÖ
  - XSS: React auto-escapes (Next.js) ‚úÖ
  - CSRF: SameSite=Strict cookies ‚úÖ
  - Authentication: Better Auth (bcrypt password hashing, cost factor 12) ‚úÖ

### Reliability
- **Uptime SLO**: 99.9% (43 minutes downtime/month)
- **Error Budget**: 0.1% of requests (e.g., 100 of 100,000 can fail)
- **Degraded Mode**: If Neon DB unavailable, return cached tasks (stale-while-revalidate, 5-minute TTL)
- **Rollback**: Blue-green deployment (<5 minutes from detection to rollback)

---

## Deployment Architecture

### Containerization
- Docker multi-stage builds (build ‚Üí runtime, minimize image size)
- Base: python:3.13-slim (constitutional requirement)

### Orchestration (Phase IV)
- Kubernetes (Minikube local, EKS production)
- Helm charts for configuration management

### CI/CD
- GitHub Actions: lint ‚Üí test ‚Üí build ‚Üí deploy
- Environments: Dev (local), Staging (Minikube), Prod (EKS)

---

## Observability

### Logging
- Format: Structured JSON (`{"timestamp": "...", "level": "INFO", "message": "...", "user_id": "...", "request_id": "..."}`)
- Levels: DEBUG (dev), INFO (prod), WARN, ERROR
- Retention: 30 days

### Metrics (Prometheus)
- request_count (counter, labels: endpoint, status_code)
- request_latency_seconds (histogram, labels: endpoint, buckets: [0.1, 0.5, 1.0, 5.0])
- active_users (gauge)
- error_rate (counter, labels: error_code)

### Alerting (Slack webhook)
- p95 latency >1s for 5 minutes ‚Üí WARN
- Error rate >5% for 5 minutes ‚Üí CRITICAL
- Uptime <99.9% in 24-hour window ‚Üí CRITICAL

---

## Risk Analysis

### Top 3 Risks

1. **Database Bottleneck**:
   - Risk: Neon DB can't handle 100 concurrent users (query latency spikes)
   - Likelihood: Medium | Impact: High
   - Mitigation: Read replicas (Phase IV), Redis cache for GET /tasks (90% hit rate target)

2. **Vendor Lock-in (Neon DB)**:
   - Risk: Pricing increase or service shutdown
   - Likelihood: Low | Impact: Medium
   - Mitigation: Standard PostgreSQL (easy migration to RDS/self-hosted), export scripts

3. **JWT Secret Compromise**:
   - Risk: Attacker gains JWT signing secret, can impersonate users
   - Likelihood: Low | Impact: Critical
   - Mitigation: Rotate secrets monthly (automated), migrate to AWS Secrets Manager (Phase V), monitor for anomalous JWT usage

---

## Constitutional Alignment

- ‚úÖ **Principle I**: Spec-Driven (plan.md follows spec.md)
- ‚úÖ **Principle II**: User Isolation (all queries filter by user_id, indexed)
- ‚úÖ **Principle VI**: Database Standards (Task model includes id, user_id, created_at, updated_at)
- ‚úÖ **Principle IX**: Code Quality (FastAPI + Pydantic enforce type safety)
- ‚úÖ **Principle X**: Testing (architecture supports dependency injection for 80% coverage)
- ‚úÖ **Principle XII**: Security (JWT AuthN, user-scoped AuthZ, OWASP mitigations)
- ‚úÖ **Principle XVIII**: Performance (p95 latency <500ms, Prometheus monitoring)

---

## ADRs Created

1. `history/adr/004-database-postgresql-neon.md` - Database choice
2. `history/adr/005-backend-fastapi.md` - Backend framework
3. `history/adr/003-authentication-better-auth.md` - Authentication library
```

---

## Constitutional Alignment

This RI enforces:

| Principle | How RI Enforces |
|-----------|-----------------|
| **I: Spec-Driven Development** | Architecture creates plan.md only after spec.md exists |
| **II: User Data Isolation** | All endpoints scoped by user_id, indexes defined, queries validated |
| **VI: Database Standards** | Data models include required fields (id, user_id, timestamps) |
| **IX: Code Quality** | Architecture enables type safety (Pydantic, TypeScript strict) |
| **X: Testing** | Architecture supports dependency injection, 80% coverage enabled |
| **XII: Security** | AuthN/AuthZ designed, secrets management planned, OWASP mitigations |
| **XVIII: Performance** | Measurable SLOs (p95 latency), monitoring strategy, cost budgets |

---

## Version History

### v1.0.0 (2025-12-12)
- Initial RI for Architect
- Created P+Q+P framework (persona, questions, principles)
- Documented 24 discovery questions across 6 categories
- Established technology selection, API design, data modeling, NFR standards
- Defined ADR criteria (3-part test), workflow, and constitutional alignment
- Integrated with /sp.plan command

---

## Related RI

- **Spec Writer RI**: Takes user input, creates spec.md (WHAT to build)
- **Task Planner RI**: Takes spec.md + plan.md, creates tasks.md (step-by-step)
- **Phase Implementer RI**: Takes tasks.md, writes code with tests

---

## Files in This RI

```
.specify/ri/skills/architect/
‚îú‚îÄ‚îÄ README.md          ‚Üê You are here (overview)
‚îú‚îÄ‚îÄ persona.md         ‚Üê Who the agent is, expertise, style
‚îú‚îÄ‚îÄ questions.md       ‚Üê 24 discovery questions
‚îî‚îÄ‚îÄ principles.md      ‚Üê Technology, API, data, NFR standards
```

---

## Feedback and Improvement

This RI evolves based on usage. After using Architect RI:

**Capture**:
- Were the questions sufficient for architecture design?
- Did the persona style (technical precision, trade-off aware) help?
- Were the principles clear and enforceable (ADR criteria, NFR standards)?
- What would improve this RI?

**Update**:
- Add new questions if gaps discovered (e.g., caching strategy, message queue patterns)
- Refine principles if ambiguity found (e.g., index strategy, migration testing)
- Update persona if communication issues arise (too technical? not enough rationale?)
- Version bump (MAJOR, MINOR, PATCH)

---

**Next RI to Create**: Phase Implementer RI (for code implementation with TDD)

**Remaining RI**: 6 total (test-guardian, security-auditor, task-planner, requirements-clarifier, constitution-reviewer, adr-creator)
